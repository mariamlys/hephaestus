#!/usr/bin/env python3
"""
Scraper pour Pixabay Music - Musiques par cat√©gorie de sport
"""

import requests
from bs4 import BeautifulSoup
import json
import time
from typing import List, Dict
import re

class PixabayMusicScraper:
    """Scraper pour r√©cup√©rer les musiques de Pixabay par cat√©gorie"""
    
    def __init__(self):
        self.base_url = "https://pixabay.com/fr/music/"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        # Cat√©gories de sport √† scraper
        self.sport_categories = {
            "course_a_pied": ["running", "jogging", "cardio", "energetic"],
            "echauffement": ["warm up", "light", "gentle"],
            "boxe": ["boxing", "intense", "aggressive", "power"],
            "marche_a_pied": ["walking", "calm", "relaxing"],
            "musculation": ["workout", "gym", "training", "motivation"]
        }
    
    def search_music(self, keywords: List[str], max_results: int = 20) -> List[Dict]:
        """
        Cherche des musiques sur Pixabay selon des mots-cl√©s
        
        Args:
            keywords: Liste de mots-cl√©s √† chercher
            max_results: Nombre maximum de r√©sultats
            
        Returns:
            Liste de dictionnaires contenant les infos des musiques
        """
        all_tracks = []
        
        for keyword in keywords:
            try:
                # URL de recherche
                search_url = f"{self.base_url}search/{keyword}/"
                
                print(f"Scraping: {search_url}")
                response = requests.get(search_url, headers=self.headers, timeout=10)
                response.raise_for_status()
                
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Trouver les √©l√©ments de musique (adapte les s√©lecteurs selon la structure r√©elle)
                music_items = soup.find_all('div', class_='item')
                
                for item in music_items[:max_results]:
                    try:
                        track_info = self._extract_track_info(item)
                        if track_info:
                            track_info['keyword'] = keyword
                            all_tracks.append(track_info)
                    except Exception as e:
                        print(f"Erreur extraction track: {e}")
                        continue
                
                # D√©lai pour √©viter de surcharger le serveur
                time.sleep(2)
                
            except Exception as e:
                print(f"Erreur scraping {keyword}: {e}")
                continue
        
        return all_tracks
    
    def _extract_track_info(self, item) -> Dict:
        """
        Extrait les informations d'une piste depuis un √©l√©ment HTML
        
        Note: Les s√©lecteurs CSS doivent √™tre adapt√©s selon la structure r√©elle de Pixabay
        """
        try:
            # √Ä ADAPTER selon la structure HTML r√©elle de Pixabay
            title = item.find('h2')
            title = title.text.strip() if title else "Unknown"
            
            # Dur√©e
            duration = item.find('span', class_='duration')
            duration = duration.text.strip() if duration else "0:00"
            
            # Artiste/Auteur
            artist = item.find('a', class_='author')
            artist = artist.text.strip() if artist else "Unknown"
            
            # Lien de t√©l√©chargement (cherche un lien avec .mp3)
            download_link = item.find('a', href=re.compile(r'\.mp3'))
            download_url = download_link['href'] if download_link else None
            
            # URL de la page
            page_link = item.find('a', class_='link')
            page_url = page_link['href'] if page_link else None
            if page_url and not page_url.startswith('http'):
                page_url = f"https://pixabay.com{page_url}"
            
            # Tags/genres
            tags = []
            tag_elements = item.find_all('a', class_='tag')
            for tag in tag_elements:
                tags.append(tag.text.strip())
            
            return {
                'title': title,
                'artist': artist,
                'duration': duration,
                'download_url': download_url,
                'page_url': page_url,
                'tags': tags
            }
            
        except Exception as e:
            print(f"Erreur extraction: {e}")
            return None
    
    def scrape_all_categories(self, tracks_per_category: int = 15) -> Dict:
        """
        Scrape toutes les cat√©gories de sport
        
        Returns:
            Dictionnaire avec les musiques par cat√©gorie
        """
        all_data = {}
        
        for category, keywords in self.sport_categories.items():
            print(f"\n=== Scraping cat√©gorie: {category} ===")
            tracks = self.search_music(keywords, max_results=tracks_per_category)
            
            # D√©duplique par titre
            unique_tracks = []
            seen_titles = set()
            for track in tracks:
                if track['title'] not in seen_titles:
                    unique_tracks.append(track)
                    seen_titles.add(track['title'])
            
            all_data[category] = unique_tracks
            print(f"‚úÖ {len(unique_tracks)} morceaux trouv√©s pour {category}")
        
        return all_data
    
    def save_to_json(self, data: Dict, filename: str = "pixabay_music_data.json"):
        """Sauvegarde les donn√©es dans un fichier JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\n‚úÖ Donn√©es sauvegard√©es dans {filename}")


def main():
    """Fonction principale pour lancer le scraping"""
    scraper = PixabayMusicScraper()
    
    print("üéµ D√©marrage du scraping Pixabay Music...")
    print("=" * 50)
    
    # Scrape toutes les cat√©gories
    music_data = scraper.scrape_all_categories(tracks_per_category=15)
    
    # Sauvegarde en JSON
    scraper.save_to_json(music_data)
    
    # Affiche un r√©sum√©
    print("\n" + "=" * 50)
    print("üìä R√âSUM√â:")
    total_tracks = sum(len(tracks) for tracks in music_data.values())
    print(f"Total de pistes: {total_tracks}")
    for category, tracks in music_data.items():
        print(f"  - {category}: {len(tracks)} pistes")


if __name__ == "__main__":
    main()
